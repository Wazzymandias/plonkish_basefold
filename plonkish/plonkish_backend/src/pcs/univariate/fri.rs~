use crate::pcs::Commitment;
use crate::piop::sum_check::{
    classic::{ClassicSumCheck, CoefficientsProver},
    eq_xy_eval, SumCheck as _, VirtualPolynomial,
};

use crate::{
    pcs::{
        multilinear::{additive, validate_input},
        AdditiveCommitment, Evaluation, Point, PolynomialCommitmentScheme,
    },
    poly::{multilinear::MultilinearPolynomial, Polynomial},
    util::{
        arithmetic::{div_ceil, inner_product, BatchInvert, Field, PrimeField, horner, steps},
	expression::{Expression,Query,Rotation},
        code::{Brakedown, BrakedownSpec, LinearCodes},
        hash::{Hash, Output},
        parallel::{num_threads, parallelize, parallelize_iter},
        transcript::{FieldTranscript, TranscriptRead, TranscriptWrite},
        BigUint, Deserialize, DeserializeOwned, Itertools, Serialize,
    },
    Error,
};
use core::ptr::addr_of;
use ff::BatchInverter;
use rayon::iter::IntoParallelIterator;
use std::{collections::HashMap, ops::Deref, iter, time::Instant};


use plonky2_util::{reverse_bits, reverse_index_bits_in_place};
use rand_chacha::{
    rand_core::{RngCore, SeedableRng},
    ChaCha12Rng,
};
use rayon::prelude::{
    IndexedParallelIterator, IntoParallelRefIterator, IntoParallelRefMutIterator, ParallelIterator,
    ParallelSlice, ParallelSliceMut,
};
use std::{borrow::Cow, marker::PhantomData, mem::size_of, slice};
type SumCheck<F> = ClassicSumCheck<CoefficientsProver<F>>;
#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct FriParams<F: PrimeField> {
    log_rate: usize,
    num_verifier_queries: usize,
    num_vars: usize,
    num_rounds: Option<usize>,
    table_w_weights: Vec<Vec<(F, F)>>,
    table: Vec<Vec<F>>,
    rng: ChaCha12Rng,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct FriProverParams<F: PrimeField> {
    log_rate: usize,
    table_w_weights: Vec<Vec<(F, F)>>,
    table: Vec<Vec<F>>,
    num_verifier_queries: usize,
    num_vars: usize,
    num_rounds: usize,
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct FriVerifierParams<F: PrimeField> {
    rng: ChaCha12Rng,
    num_vars: usize,
    log_rate: usize,
    num_verifier_queries: usize,
    num_rounds: usize,
    table_w_weights: Vec<Vec<(F, F)>>,
}

#[derive(Clone, Debug, Default, Serialize, Deserialize)]
#[serde(bound(serialize = "F: Serialize", deserialize = "F: DeserializeOwned"))]
pub struct FriCommitment<F, H: Hash> {
    codeword: Vec<F>,
    codeword_tree: Vec<Vec<Output<H>>>,
    bh_evals: Vec<F>,
}

impl<F: PrimeField, H: Hash> FriCommitment<F, H> {
    fn from_root(root: Output<H>) -> Self {
        Self {
            codeword: Vec::new(),
            codeword_tree: vec![vec![root]],
            bh_evals: Vec::new(),
        }
    }
}
impl<F: PrimeField, H: Hash> PartialEq for FriCommitment<F, H> {
    fn eq(&self, other: &Self) -> bool {
        self.codeword.eq(&other.codeword)
            && self.codeword_tree.eq(&other.codeword_tree)
            && self.bh_evals.eq(&other.bh_evals)
    }
}

impl<F: PrimeField, H: Hash> Eq for FriCommitment<F, H> {}
#[derive(Debug)]
pub struct Fri<F: PrimeField, H: Hash>(PhantomData<(F, H)>);

impl<F: PrimeField, H: Hash> Clone for Fri<F, H> {
    fn clone(&self) -> Self {
        Self(PhantomData)
    }
}

impl<F: PrimeField, H: Hash> AsRef<[Output<H>]> for FriCommitment<F, H> {
    fn as_ref(&self) -> &[Output<H>] {
        let root = &self.codeword_tree[self.codeword_tree.len() - 1][0];
        slice::from_ref(root)
    }
}
impl<F: PrimeField, H: Hash> AdditiveCommitment<F> for FriCommitment<F, H> {
    fn sum_with_scalar<'a>(
        scalars: impl IntoIterator<Item = &'a F> + 'a,
        bases: impl IntoIterator<Item = &'a Self> + 'a,
    ) -> Self {
        let bases = bases.into_iter().collect_vec();
        let mut new_codeword = Vec::with_capacity(bases.len());
        let mut new_bh_eval = Vec::new();

        let scalars = scalars.into_iter().collect_vec();
        let bases = bases.into_iter().collect_vec();
        let k = bases[0].bh_evals.len();
        for i in 0..bases[0].codeword.len() {
            let mut lc = F::ZERO;
            let mut bh_lc = F::ZERO;
            for j in 0..bases.len() {
                lc += *scalars[j] * bases[j].codeword[i];
                if (i < k) {
                    bh_lc += *scalars[j] * bases[j].bh_evals[i];
                }
            }
            new_codeword.push(lc);
            new_bh_eval.push(bh_lc);
        }

        let tree = merkelize::<F, H>(&new_codeword);

        Self {
            codeword: new_codeword,
            bh_evals: new_bh_eval,
            codeword_tree: tree,
        }
    }
}
impl<F, H> PolynomialCommitmentScheme<F> for Fri<F, H>
where
    F: PrimeField + Serialize + DeserializeOwned,
    H: Hash,
{
    type Param = FriParams<F>;
    type ProverParam = FriProverParams<F>;
    type VerifierParam = FriVerifierParams<F>;
    type Polynomial = UnivariatePolynomial<F>;
    type Commitment = BasefoldCommitment<F, H>;
    type CommitmentChunk = Output<H>;

    fn setup(poly_size: usize, _: usize, rng: impl RngCore) -> Result<Self::Param, Error> {
        let rate = 3;
        let lg_n: usize = rate + log2_strict(poly_size);
        let mut test_rng = ChaCha12Rng::from_entropy();
        let now = Instant::now();

        let bytes = (F::NUM_BITS as usize).next_power_of_two() * (1 << lg_n) / 8;
        let mut dest: Vec<u8> = vec![0u8; bytes];
        test_rng.fill_bytes(&mut dest);

        let flat_table: Vec<F> = dest
            .par_chunks_exact((F::NUM_BITS as usize).next_power_of_two() / 8)
            .map(|chunk| from_raw_bytes::<F>(&chunk.to_vec()))
            .collect::<Vec<_>>();

        assert_eq!(flat_table.len(), 1 << lg_n);

        let mut weights: Vec<F> = flat_table
            .par_iter()
            .map(|el| F::ZERO - *el - *el)
            .collect();

        let mut scratch_space = vec![F::ZERO; weights.len()];
        BatchInverter::invert_with_external_scratch(&mut weights, &mut scratch_space);

        let mut flat_table_w_weights = flat_table
            .iter()
            .zip(weights)
            .map(|(el, w)| (*el, w))
            .collect_vec();

        let mut unflattened_table_w_weights = vec![Vec::new(); lg_n];
        let mut unflattened_table = vec![Vec::new(); lg_n];

        let mut level_weights = flat_table_w_weights[0..2].to_vec();
        reverse_index_bits_in_place(&mut level_weights);
        unflattened_table_w_weights[0] = level_weights;

        unflattened_table[0] = flat_table[0..2].to_vec();
        for i in 1..lg_n {
            unflattened_table[i] = flat_table[(1 << i)..(1 << (i + 1))].to_vec();
            let mut level = flat_table_w_weights[(1 << i)..(1 << (i + 1))].to_vec();
            reverse_index_bits_in_place(&mut level);
            unflattened_table_w_weights[i] = level;
        }
        Ok(BasefoldParams {
            log_rate: rate,
            num_verifier_queries: 196,
            num_vars: log2_strict(poly_size),
            num_rounds: Some(log2_strict(poly_size) - 3),
            table_w_weights: unflattened_table_w_weights,
            table: unflattened_table,
            rng: test_rng.clone(),
        })
    }
    fn trim(
        param: &Self::Param,
        poly_size: usize,
        batch_size: usize,
    ) -> Result<(Self::ProverParam, Self::VerifierParam), Error> {
        let mut rounds = param.num_vars;
        if param.num_rounds.is_some() {
            rounds = param.num_rounds.unwrap();
        }

        Ok((
            BasefoldProverParams {
                log_rate: param.log_rate,
                table_w_weights: param.table_w_weights.clone(),
                table: param.table.clone(),
                num_verifier_queries: param.num_verifier_queries,
                num_vars: param.num_vars,
                num_rounds: rounds,
            },
            BasefoldVerifierParams {
                rng: param.rng.clone(),
                num_vars: param.num_vars,
                log_rate: param.log_rate,
                num_verifier_queries: param.num_verifier_queries,
                num_rounds: rounds,
                table_w_weights: param.table_w_weights.clone(),
            },
        ))
    }

    fn commit(pp: &Self::ProverParam, poly: &Self::Polynomial) -> Result<Self::Commitment, Error> {
        let now = Instant::now();
        let (coeffs, mut bh_evals) =
            interpolate_over_boolean_hypercube_with_copy(&poly.evals().to_vec());

        let now = Instant::now();
        let mut commitment = evaluate_over_foldable_domain(pp.log_rate, coeffs.clone(), &pp.table);

        reverse_index_bits_in_place(&mut bh_evals);
        reverse_index_bits_in_place(&mut commitment);

        let now = Instant::now();
        let tree = merkelize::<F, H>(&commitment);

        Ok(Self::Commitment {
            codeword: commitment,
            codeword_tree: tree,
            bh_evals: bh_evals,
        })
    }

    fn batch_commit_and_write<'a>(
        pp: &Self::ProverParam,
        polys: impl IntoIterator<Item = &'a Self::Polynomial>,
        transcript: &mut impl TranscriptWrite<Self::CommitmentChunk, F>,
    ) -> Result<Vec<Self::Commitment>, Error>
    where
        Self::Polynomial: 'a,
    {
        let comms = Self::batch_commit(pp, polys)?;
        let mut roots = Vec::with_capacity(comms.len());

        comms.iter().for_each(|comm| {
            let root = &comm.codeword_tree[comm.codeword_tree.len() - 1][0];
            roots.push(root);
        });

        transcript.write_commitments(roots).unwrap();
        Ok(comms)
    }

    fn batch_commit<'a>(
        pp: &Self::ProverParam,
        polys: impl IntoIterator<Item = &'a Self::Polynomial>,
    ) -> Result<Vec<Self::Commitment>, Error> {
        polys
            .into_iter()
            .map(|poly| {
                let comm = Self::commit(pp, poly);
                comm
            })
            .collect()
    }

    fn open(
        pp: &Self::ProverParam,
        poly: &Self::Polynomial,
        comm: &Self::Commitment,
        point: &Point<F, Self::Polynomial>,
        eval: &F,
        transcript: &mut impl TranscriptWrite<Self::CommitmentChunk, F>,
    ) -> Result<(), Error> {
        let (trees, sum_check_oracles, mut oracles, bh_evals, eq, eval) = commit_phase(
            &point,
            &comm,
            transcript,
            pp.num_vars,
            pp.num_rounds,
            &pp.table_w_weights,
        );

        let (queried_els, queries_usize_) =
            query_phase(transcript, &comm, &oracles, pp.num_verifier_queries);

        // a proof consists of roots, merkle paths, query paths, sum check oracles, eval, and final oracle
        //write sum check oracles

        transcript
            .write_field_elements(&sum_check_oracles.into_iter().flatten().collect::<Vec<F>>()); //write sumcheck
        transcript.write_field_element(&eval); //write eval

        if pp.num_rounds < pp.num_vars {
            transcript.write_field_elements(&bh_evals); //write bh_evals
            transcript.write_field_elements(&eq); //write eq
        }

        //write final oracle
        let mut final_oracle = oracles.pop().unwrap();
        transcript.write_field_elements(&final_oracle);

        //write query paths
        queried_els
            .iter()
            .map(|q| &q.0)
            .flatten()
            .for_each(|query| {
                transcript.write_field_element(&query.0);
                transcript.write_field_element(&query.1);
            });

        //write merkle paths
        queried_els.iter().for_each(|query| {
            let indices = &query.1;
            indices.into_iter().enumerate().for_each(|(i, q)| {
                if (i == 0) {
                    write_merkle_path::<H, F>(&comm.codeword_tree, *q, transcript);
                } else {
                    write_merkle_path::<H, F>(&trees[i - 1], *q, transcript);
                }
            })
        });

        Ok(())
    }

    fn batch_open<'a>(
        pp: &Self::ProverParam,
        polys: impl IntoIterator<Item = &'a Self::Polynomial>,
        comms: impl IntoIterator<Item = &'a Self::Commitment>,
        points: &[Point<F, Self::Polynomial>],
        evals: &[Evaluation<F>],
        transcript: &mut impl TranscriptWrite<Self::CommitmentChunk, F>,
    ) -> Result<(), Error> {
        let polys = polys.into_iter().collect_vec();
        let comms = comms.into_iter().collect_vec();

        validate_input("batch open", pp.num_vars, polys.clone(), points)?;

        let ell = evals.len().next_power_of_two().ilog2() as usize;
        let t = transcript.squeeze_challenges(ell);

        let eq_xt = MultilinearPolynomial::eq_xy(&t);
        let merged_polys = evals.iter().zip(eq_xt.evals().iter()).fold(
            vec![(F::ONE, Cow::<MultilinearPolynomial<_>>::default()); points.len()],
            |mut merged_polys, (eval, eq_xt_i)| {
                if merged_polys[eval.point()].1.is_zero() {
                    merged_polys[eval.point()] = (*eq_xt_i, Cow::Borrowed(polys[eval.poly()]));
                } else {
                    let coeff = merged_polys[eval.point()].0;
                    if coeff != F::ONE {
                        merged_polys[eval.point()].0 = F::ONE;
                        *merged_polys[eval.point()].1.to_mut() *= &coeff;
                    }
                    *merged_polys[eval.point()].1.to_mut() += (eq_xt_i, polys[eval.poly()]);
                }
                merged_polys
            },
        );

        let unique_merged_polys = merged_polys
            .iter()
            .unique_by(|(_, poly)| addr_of!(*poly.deref()))
            .collect_vec();
        let unique_merged_poly_indices = unique_merged_polys
            .iter()
            .enumerate()
            .map(|(idx, (_, poly))| (addr_of!(*poly.deref()), idx))
            .collect::<HashMap<_, _>>();
        let expression = merged_polys
            .iter()
            .enumerate()
            .map(|(idx, (scalar, poly))| {
                let poly = unique_merged_poly_indices[&addr_of!(*poly.deref())];
                Expression::<F>::eq_xy(idx)
                    * Expression::Polynomial(Query::new(poly, Rotation::cur()))
                    * scalar
            })
            .sum();
        let virtual_poly = VirtualPolynomial::new(
            &expression,
            unique_merged_polys.iter().map(|(_, poly)| poly.deref()),
            &[],
            points,
        );
        let tilde_gs_sum =
            inner_product(evals.iter().map(Evaluation::value), &eq_xt[..evals.len()]);
        let (challenges, _) =
            SumCheck::prove(&(), pp.num_vars, virtual_poly, tilde_gs_sum, transcript)?;

        let eq_xy_evals = points
            .iter()
            .map(|point| eq_xy_eval(&challenges, point))
            .collect_vec();
        let g_prime = merged_polys
            .into_iter()
            .zip(eq_xy_evals.iter())
            .map(|((scalar, poly), eq_xy_eval)| (scalar * eq_xy_eval, poly.into_owned()))
            .sum::<MultilinearPolynomial<_>>();

        let (comm, eval) = if cfg!(feature = "sanity-check") {
            let scalars = evals
                .iter()
                .zip(eq_xt.evals())
                .map(|(eval, eq_xt_i)| eq_xy_evals[eval.point()] * eq_xt_i)
                .collect_vec();
            let bases = evals.iter().map(|eval| comms[eval.poly()]);
            let comm = Self::Commitment::sum_with_scalar(&scalars, bases);
            (comm, g_prime.evaluate(&challenges))
        } else {
            (Self::Commitment::default(), F::ZERO)
        };

        let point = challenges;

        let (trees, sum_check_oracles, mut oracles, bh_evals, eq, eval) = commit_phase(
            &point,
            &comm,
            transcript,
            pp.num_vars,
            pp.num_rounds,
            &pp.table_w_weights,
        );

        if pp.num_rounds < pp.num_vars {
            transcript.write_field_elements(&bh_evals);
            transcript.write_field_elements(&eq);
        }

        let (queried_els, queries_usize) = query_phase(transcript, &comm, &oracles, pp.num_verifier_queries);

        let mut individual_queries: Vec<Vec<(F, F)>> = Vec::with_capacity(queries_usize.len());
        let mut individual_paths: Vec<Vec<Vec<(Output<H>, Output<H>)>>> =
            Vec::with_capacity(queries_usize.len());
        for query in &queries_usize {
            let mut comm_queries = Vec::with_capacity(evals.len());
            let mut comm_paths = Vec::with_capacity(evals.len());
            for eval in evals {
                let c = comms[eval.poly()];
                let mut p0 = *query;
                let temp = p0;
                let mut p1 = p0 ^ 1;
                if (p1 < p0) {
                    p0 = p1;
                    p1 = temp;
                }
                let leaves = (c.codeword[p0], c.codeword[p1]);
                let path = get_merkle_path::<H, F>(&c.codeword_tree, *query, true);

                comm_queries.push(leaves);
                comm_paths.push(path);
            }

            individual_queries.push(comm_queries);
            individual_paths.push(comm_paths);
        }

        let merkle_paths: Vec<Vec<Vec<(Output<H>, Output<H>)>>> = queried_els
            .iter()
            .map(|query| {
                let indices = &query.1;
                indices
                    .into_iter()
                    .enumerate()
                    .map(|(i, q)| {
                        if (i == 0) {
                            return get_merkle_path::<H, F>(&comm.codeword_tree, *q, false);
                        } else {
                            return get_merkle_path::<H, F>(&trees[i - 1], *q, false);
                        }
                    })
                    .collect_vec()
            })
            .collect_vec();

        // a proof consists of roots, merkle paths, query paths, sum check oracles, eval, and final oracle
        //write individual commitment queries for batching
        //queries for batch
        individual_queries.iter().flatten().for_each(|(f1, f2)| {
            transcript.write_field_element(f1).unwrap();
            transcript.write_field_element(f2).unwrap();
        });
        //paths for batch
        individual_paths
            .iter()
            .flatten()
            .flatten()
            .for_each(|(h1, h2)| {
                transcript.write_commitment(h1);
                transcript.write_commitment(h2);
            });

        //write sum check oracles
        transcript.write_field_elements(sum_check_oracles.iter().flatten());
        //write eval
        transcript.write_field_element(&eval);
        //write final oracle
        transcript.write_field_elements(oracles.pop().unwrap().iter().collect_vec());
        //write query paths
        queried_els
            .iter()
            .map(|q| &q.0)
            .flatten()
            .for_each(|query| {
                transcript.write_field_element(&query.0);
                transcript.write_field_element(&query.1);
            });
        //write merkle paths
        merkle_paths
            .iter()
            .flatten()
            .flatten()
            .for_each(|(h1, h2)| {
                transcript.write_commitment(h1);
                transcript.write_commitment(h2);
            });

        Ok(())
    }

    fn read_commitments(
        _: &Self::VerifierParam,
        num_polys: usize,
        transcript: &mut impl TranscriptRead<Self::CommitmentChunk, F>,
    ) -> Result<Vec<Self::Commitment>, Error> {
        let roots = transcript.read_commitments(num_polys).unwrap();

        Ok(roots
            .iter()
            .map(|r| BasefoldCommitment::from_root(r.clone()))
            .collect_vec())
    }

    fn verify(
        vp: &Self::VerifierParam,
        comm: &Self::Commitment,
        point: &Point<F, Self::Polynomial>,
        eval: &F,
        transcript: &mut impl TranscriptRead<Self::CommitmentChunk, F>,
    ) -> Result<(), Error> {
        let field_size = 255;
        let n = (1 << (vp.num_vars + vp.log_rate));
        //read first $(num_var - 1) commitments

        let mut fold_challenges: Vec<F> = Vec::with_capacity(vp.num_vars);
        let mut size = 0;
        let mut roots = Vec::new();
        for i in 0..vp.num_rounds {
            roots.push(transcript.read_commitment().unwrap());
            fold_challenges.push(transcript.squeeze_challenge());
        }
        size = size + 256 * vp.num_rounds;
        //read last commitment
        transcript.read_commitment().unwrap();

        let mut query_challenges = transcript.squeeze_challenges(vp.num_verifier_queries);
        //read sum check oracles
        let mut sum_check_oracles: Vec<Vec<F>> = transcript
            .read_field_elements(3 * (vp.num_rounds + 1))
            .unwrap()
            .chunks(3)
            .map(|c| c.to_vec())
            .collect_vec();

        size = size + field_size * (3 * (vp.num_rounds + 1)); // dont need last sumcheck oracle in proof
                                                              //read eval

        let eval = &transcript.read_field_element().unwrap(); //do not need eval in proof

        let mut bh_evals = Vec::new();
        let mut eq = Vec::new();
        if vp.num_rounds < vp.num_vars {
            bh_evals = transcript
                .read_field_elements(1 << (vp.num_vars - vp.num_rounds))
                .unwrap();
            eq = transcript
                .read_field_elements(1 << (vp.num_vars - vp.num_rounds))
                .unwrap();
            size = size + field_size * (bh_evals.len() + eq.len());
        }

        //read final oracle
        let mut final_oracle = transcript
            .read_field_elements(1 << (vp.num_vars - vp.num_rounds + vp.log_rate))
            .unwrap();

        size = size + field_size * final_oracle.len();
        //read query paths
        let num_queries = vp.num_verifier_queries * 2 * (vp.num_rounds + 1);

        let all_qs = transcript.read_field_elements(num_queries).unwrap();

        size = size + (num_queries - 2) * field_size;
        println!("size for all iop queries {:?}", size);

        let i_qs = all_qs.chunks((vp.num_rounds + 1) * 2).collect_vec();

        assert_eq!(i_qs.len(), vp.num_verifier_queries);

        let mut queries = i_qs.iter().map(|q| q.chunks(2).collect_vec()).collect_vec();

        assert_eq!(queries.len(), vp.num_verifier_queries);

        //read merkle paths

        let mut query_merkle_paths: Vec<Vec<Vec<Vec<Output<H>>>>> =
            Vec::with_capacity(vp.num_verifier_queries);
        let query_merkle_paths: Vec<Vec<Vec<Vec<Output<H>>>>> = (0..vp.num_verifier_queries)
            .into_iter()
            .map(|i| {
                let mut merkle_paths: Vec<Vec<Vec<Output<H>>>> =
                    Vec::with_capacity(vp.num_rounds + 1);
                for round in 0..(vp.num_rounds + 1) {
                    let mut merkle_path: Vec<Output<H>> = transcript
                        .read_commitments(2 * (vp.num_vars - round + vp.log_rate - 1))
                        .unwrap();
                    size = size + 256 * (2 * (vp.num_vars - round + vp.log_rate - 1));

                    let chunked_path: Vec<Vec<Output<H>>> =
                        merkle_path.chunks(2).map(|c| c.to_vec()).collect_vec();

                    merkle_paths.push(chunked_path);
                }
                merkle_paths
            })
            .collect();

        verifier_query_phase::<F, H>(
            &query_challenges,
            &query_merkle_paths,
            &sum_check_oracles,
            &fold_challenges,
            &queries,
            vp.num_rounds,
            vp.num_vars,
            vp.log_rate,
            &roots,
            vp.rng.clone(),
            &eval,
        );

        println!("Basefold effective proof size {:?}", size);
        virtual_open(
            vp.num_vars,
            vp.num_rounds,
            &mut eq,
            &mut bh_evals,
            &mut final_oracle,
            point,
            &mut fold_challenges,
            &vp.table_w_weights,
            &mut sum_check_oracles,
        );

        Ok(())
    }

    fn batch_verify<'a>(
        vp: &Self::VerifierParam,
        comms: impl IntoIterator<Item = &'a Self::Commitment>,
        points: &[Point<F, Self::Polynomial>],
        evals: &[Evaluation<F>],
        transcript: &mut impl TranscriptRead<Self::CommitmentChunk, F>,
    ) -> Result<(), Error> {
        let comms = comms.into_iter().collect_vec();
        validate_input("batch verify", vp.num_vars, [], points)?;

        let ell = evals.len().next_power_of_two().ilog2() as usize;
        let t = transcript.squeeze_challenges(ell);

        let eq_xt = MultilinearPolynomial::eq_xy(&t);
        let tilde_gs_sum =
            inner_product(evals.iter().map(Evaluation::value), &eq_xt[..evals.len()]);

        let (g_prime_eval, verify_point) =
            SumCheck::verify(&(), vp.num_vars, 2, tilde_gs_sum, transcript)?;

        let eq_xy_evals = points
            .iter()
            .map(|point| eq_xy_eval(&verify_point, point))
            .collect_vec();

        //start of verify
        let n = (1 << (vp.num_vars + vp.log_rate));
        //read first $(num_var - 1) commitments
        let mut roots: Vec<Output<H>> = Vec::with_capacity(vp.num_rounds + 1);
        let mut fold_challenges: Vec<F> = Vec::with_capacity(vp.num_rounds);
        for i in 0..vp.num_rounds {
            roots.push(transcript.read_commitment().unwrap());
            fold_challenges.push(transcript.squeeze_challenge());
        }

        //read last commitment
        transcript.read_commitment().unwrap();

        let mut bh_evals = Vec::new();
        let mut eq = Vec::new();
        if vp.num_rounds < vp.num_vars {
            bh_evals = transcript
                .read_field_elements(1 << (vp.num_vars - vp.num_rounds))
                .unwrap();
            eq = transcript
                .read_field_elements(1 << (vp.num_vars - vp.num_rounds))
                .unwrap();
        }

        let mut query_challenges = transcript.squeeze_challenges(vp.num_verifier_queries);

        let mut ind_queries = Vec::with_capacity(vp.num_verifier_queries);
        let mut count = 0;
        for i in 0..vp.num_verifier_queries {
            let mut comms_queries = Vec::with_capacity(evals.len());
            for j in 0..evals.len() {
                let queries = transcript.read_field_elements(2).unwrap();

                comms_queries.push(queries);
            }

            ind_queries.push(comms_queries);
        }

        //read merkle paths
        let mut batch_paths = Vec::with_capacity(vp.num_verifier_queries);
        let mut count = 0;
        for i in 0..vp.num_verifier_queries {
            let mut comms_merkle_paths = Vec::with_capacity(evals.len());
            for j in 0..evals.len() {
                let merkle_path = transcript
                    .read_commitments(2 * (vp.num_vars + vp.log_rate))
                    .unwrap();
                let chunked_path = merkle_path.chunks(2).map(|c| c.to_vec()).collect_vec();

                comms_merkle_paths.push(chunked_path);
            }

            batch_paths.push(comms_merkle_paths);
        }

        let mut count = 0;

        let mut sum_check_oracles: Vec<Vec<F>> = transcript
            .read_field_elements(3 * (vp.num_rounds + 1))
            .unwrap()
            .chunks(3)
            .map(|c| c.to_vec())
            .collect_vec();

        //read eval
        let eval = transcript.read_field_element().unwrap();

        //read final oracle
        let mut final_oracle = transcript
            .read_field_elements(1 << (vp.num_vars - vp.num_rounds + vp.log_rate))
            .unwrap();

        //read query paths
        let num_queries = vp.num_verifier_queries * 2 * (vp.num_rounds + 1);

        let all_qs = transcript.read_field_elements(num_queries).unwrap();

        let i_qs = all_qs.chunks((vp.num_rounds + 1) * 2).collect_vec();

        assert_eq!(i_qs.len(), vp.num_verifier_queries);

        let mut queries = i_qs.iter().map(|q| q.chunks(2).collect_vec()).collect_vec();

        assert_eq!(queries[0][0].len(), 2);

        let scalars = evals
            .iter()
            .zip(eq_xt.evals())
            .map(|(eval, eq_xt_i)| eq_xy_evals[eval.point()] * eq_xt_i)
            .collect_vec();

        for (i, query) in queries.iter().enumerate() {
            let mut lc0 = F::ZERO;
            let mut lc1 = F::ZERO;
            for j in 0..scalars.len() {
                lc0 += scalars[j] * ind_queries[i][j][0];
                lc1 += scalars[j] * ind_queries[i][j][1];
            }
            assert_eq!(query[0][0], lc0);
            assert_eq!(query[0][1], lc1);
        }

        //start regular verify on the proof in transcript

        let mut query_merkle_paths: Vec<Vec<Vec<Vec<Output<H>>>>> =
            Vec::with_capacity(vp.num_verifier_queries);
        for i in 0..vp.num_verifier_queries {
            let mut merkle_paths: Vec<Vec<Vec<Output<H>>>> = Vec::with_capacity(vp.num_rounds + 1);
            for round in 0..(vp.num_rounds + 1) {
                let merkle_path: Vec<Output<H>> = transcript
                    .read_commitments(2 * (vp.num_vars - round + vp.log_rate - 1))
                    .unwrap();
                let chunked_path: Vec<Vec<Output<H>>> =
                    merkle_path.chunks(2).map(|c| c.to_vec()).collect_vec();

                merkle_paths.push(chunked_path);
            }
            query_merkle_paths.push(merkle_paths);
        }

        let queries_usize = verifier_query_phase::<F, H>(
            &query_challenges,
            &query_merkle_paths,
            &sum_check_oracles,
            &fold_challenges,
            &queries,
            vp.num_rounds,
            vp.num_vars,
            vp.log_rate,
            &roots,
            vp.rng.clone(),
            &eval,
        );

        for vq in 0..vp.num_verifier_queries {
            for cq in 0..ind_queries[vq].len() {
                let tree = &comms[evals[cq].poly].codeword_tree;
                assert_eq!(
                    tree[tree.len() - 1][0],
                    batch_paths[vq][cq].pop().unwrap().pop().unwrap()
                );

                authenticate_merkle_path::<H, F>(
                    &batch_paths[vq][cq],
                    (ind_queries[vq][cq][0], ind_queries[vq][cq][1]),
                    queries_usize[vq],
                );

                count += 1;
            }
        }
        virtual_open(
            vp.num_vars,
            vp.num_rounds,
            &mut eq,
            &mut bh_evals,
            &mut final_oracle,
            &verify_point,
            &mut fold_challenges,
            &vp.table_w_weights,
            &mut sum_check_oracles,
        );

        Ok(())
    }
}

pub fn evaluate_over_foldable_domain<F: PrimeField>(
    log_rate: usize,
    mut coeffs: Vec<F>,
    table: &Vec<Vec<F>>,
) -> Vec<F> {
    //iterate over array, replacing even indices with (evals[i] - evals[(i+1)])
    let k = coeffs.len();
    let logk = log2_strict(k);
    let cl = 1 << (logk + log_rate);
    let rate = 1 << log_rate;
    let mut coeffs_with_rep = Vec::with_capacity(cl);
    for i in 0..cl {
        coeffs_with_rep.push(F::ZERO);
    }

    let now = Instant::now();
    for i in 0..k {
        for j in 0..rate {
            coeffs_with_rep[i * rate + j] = coeffs[i];
        }
    }

    let mut chunk_size = rate;
    for i in 0..logk {
        let level = &table[i + log_rate];
        chunk_size = chunk_size << 1;
        assert_eq!(level.len(), chunk_size >> 1);
        <Vec<F> as AsMut<[F]>>::as_mut(&mut coeffs_with_rep)
            .par_chunks_mut(chunk_size)
            .for_each(|chunk| {
                let half_chunk = chunk_size >> 1;
                for j in half_chunk..chunk_size {
                    let rhs = chunk[j] * level[j - half_chunk];
                    chunk[j] = chunk[j - half_chunk] - rhs;
                    chunk[j - half_chunk] = chunk[j - half_chunk] + rhs;
                }
            });
    }
    coeffs_with_rep
}

fn interpolate_over_boolean_hypercube_with_copy<F: PrimeField>(evals: &Vec<F>) -> (Vec<F>, Vec<F>) {
    //iterate over array, replacing even indices with (evals[i] - evals[(i+1)])
    let n = log2_strict(evals.len());
    let mut coeffs = vec![F::ZERO; evals.len()];
    let mut new_evals = vec![F::ZERO; evals.len()];

    let mut j = 0;
    while (j < coeffs.len()) {
        new_evals[j] = evals[j];
        new_evals[j + 1] = evals[j + 1];

        coeffs[j + 1] = evals[j + 1] - evals[j];
        coeffs[j] = evals[j];
        j += 2
    }

    for i in 2..n + 1 {
        let chunk_size = 1 << i;
        coeffs.par_chunks_mut(chunk_size).for_each(|chunk| {
            let half_chunk = chunk_size >> 1;
            for j in half_chunk..chunk_size {
                chunk[j] = chunk[j] - chunk[j - half_chunk];
            }
        });
    }

    (coeffs, new_evals)
}

//helper function
fn rand_vec<F: PrimeField>(size: usize, mut rng: &mut ChaCha12Rng) -> Vec<F> {
    (0..size).map(|_| F::random(&mut rng)).collect()
}
fn rand_chacha<F: PrimeField>(mut rng: &mut ChaCha12Rng) -> F {
    let bytes = (F::NUM_BITS as usize).next_power_of_two() / 8;
    let mut dest: Vec<u8> = vec![0u8; bytes];
    rng.fill_bytes(&mut dest);
    from_raw_bytes::<F>(&dest)
}

pub fn log2_strict(n: usize) -> usize {
    let res = n.trailing_zeros();
    assert!(n.wrapping_shr(res) == 1, "Not a power of two: {n}");
    // Tell the optimizer about the semantics of `log2_strict`. i.e. it can replace `n` with
    // `1 << res` and vice versa.

    res as usize
}

fn merkelize<F: PrimeField, H: Hash>(values: &Vec<F>) -> Vec<Vec<Output<H>>> {
    let log_v = log2_strict(values.len());
    let mut tree = Vec::with_capacity(log_v);
    let mut hashes = vec![Output::<H>::default(); (values.len() >> 1)];
    let method1 = Instant::now();
    hashes.par_iter_mut().enumerate().for_each(|(i, mut hash)| {
        let mut hasher = H::new();
        hasher.update_field_element(&values[i + i]);
        hasher.update_field_element(&values[i + i + 1]);
        *hash = hasher.finalize_fixed();
    });

    tree.push(hashes);

    let now = Instant::now();
    for i in 1..(log_v) {
        let oracle = tree[i - 1]
            .par_chunks_exact(2)
            .map(|ys| {
                let mut hasher = H::new();
                let mut hash = Output::<H>::default();
                hasher.update(&ys[0]);
                hasher.update(&ys[1]);
                hasher.finalize_fixed()
            })
            .collect::<Vec<_>>();

        tree.push(oracle);
    }
    tree
}

pub fn build_eq_x_r_vec<F: PrimeField>(r: &[F]) -> Option<Vec<F>> {
    // we build eq(x,r) from its evaluations
    // we want to evaluate eq(x,r) over x \in {0, 1}^num_vars
    // for example, with num_vars = 4, x is a binary vector of 4, then
    //  0 0 0 0 -> (1-r0)   * (1-r1)    * (1-r2)    * (1-r3)
    //  1 0 0 0 -> r0       * (1-r1)    * (1-r2)    * (1-r3)
    //  0 1 0 0 -> (1-r0)   * r1        * (1-r2)    * (1-r3)
    //  1 1 0 0 -> r0       * r1        * (1-r2)    * (1-r3)
    //  ....
    //  1 1 1 1 -> r0       * r1        * r2        * r3
    // we will need 2^num_var evaluations

    let mut eval = Vec::new();
    build_eq_x_r_helper(r, &mut eval);

    Some(eval)
}

/// A helper function to build eq(x, r) recursively.
/// This function takes `r.len()` steps, and for each step it requires a maximum
/// `r.len()-1` multiplications.
fn build_eq_x_r_helper<F: PrimeField>(r: &[F], buf: &mut Vec<F>) {
    assert!(!r.is_empty(), "r length is 0");

    if r.len() == 1 {
        // initializing the buffer with [1-r_0, r_0]
        buf.push(F::ONE - r[0]);
        buf.push(r[0]);
    } else {
        build_eq_x_r_helper(&r[1..], buf);

        // suppose at the previous step we received [b_1, ..., b_k]
        // for the current step we will need
        // if x_0 = 0:   (1-r0) * [b_1, ..., b_k]
        // if x_0 = 1:   r0 * [b_1, ..., b_k]
        // let mut res = vec![];
        // for &b_i in buf.iter() {
        //     let tmp = r[0] * b_i;
        //     res.push(b_i - tmp);
        //     res.push(tmp);
        // }
        // *buf = res;

        let mut res = vec![F::ZERO; buf.len() << 1];
        res.par_iter_mut().enumerate().for_each(|(i, val)| {
            let bi = buf[i >> 1];
            let tmp = r[0] * bi;
            if i & 1 == 0 {
                *val = bi - tmp;
            } else {
                *val = tmp;
            }
        });
        *buf = res;
    }
}

fn sum_check_first_round<F: PrimeField>(mut eq: &mut Vec<F>, mut bh_values: &mut Vec<F>) -> Vec<F> {
    one_level_interp_hc(&mut eq);
    one_level_interp_hc(&mut bh_values);

    p_i(&bh_values, &eq)
}

pub fn one_level_interp_hc<F: PrimeField>(mut evals: &mut Vec<F>) {
    if (evals.len() == 1) {
        return;
    }
    evals.par_chunks_mut(2).for_each(|chunk| {
        chunk[1] = chunk[1] - chunk[0];
    });
}

pub fn one_level_eval_hc<F: PrimeField>(mut evals: &mut Vec<F>, challenge: F) {
    evals.par_chunks_mut(2).for_each(|chunk| {
        chunk[1] = chunk[0] + challenge * chunk[1];
    });
    let mut index = 0;
    evals.retain(|v| {
        index += 1;
        (index - 1) % 2 == 1
    });
}

pub fn p_i<F: PrimeField>(mut evals: &Vec<F>, eq: &Vec<F>) -> Vec<F> {
    if (evals.len() == 1) {
        return vec![evals[0], evals[0], evals[0]];
    }
    //evals coeffs
    let mut coeffs = vec![F::ZERO, F::ZERO, F::ZERO];
    let mut i = 0;
    while (i < evals.len()) {
        coeffs[0] += evals[i] * eq[i];
        coeffs[1] += evals[i + 1] * eq[i] + evals[i] * eq[i + 1];
        coeffs[2] += evals[i + 1] * eq[i + 1];
        i += 2;
    }

    coeffs
}

fn sum_check_challenge_round<F: PrimeField>(
    mut eq: &mut Vec<F>,
    mut bh_values: &mut Vec<F>,
    challenge: F,
) -> Vec<F> {
    one_level_eval_hc(&mut bh_values, challenge);
    one_level_eval_hc(&mut eq, challenge);

    one_level_interp_hc(&mut eq);
    one_level_interp_hc(&mut bh_values);

    p_i(&bh_values, &eq)
}

fn basefold_one_round_by_interpolation_weights<F: PrimeField>(
    table: &Vec<Vec<(F, F)>>,
    table_offset: usize,
    values: &Vec<F>,
    challenge: F,
) -> Vec<F> {
    let level = &table[table.len() - 1 - table_offset];
    values
        .par_chunks_exact(2)
        .enumerate()
        .map(|(i, ys)| {
            interpolate2_weights::<F>(
                [(level[i].0, ys[0]), (-(level[i].0), ys[1])],
                level[i].1,
                challenge,
            )
        })
        .collect::<Vec<_>>()
}

fn basefold_get_query<F: PrimeField>(
    first_oracle: &Vec<F>,
    oracles: &Vec<Vec<F>>,
    mut x_index: usize,
) -> (Vec<(F, F)>, Vec<usize>) {
    let mut queries = Vec::with_capacity(oracles.len() + 1);
    let mut indices = Vec::with_capacity(oracles.len() + 1);

    let mut p0 = x_index;
    let mut p1 = x_index ^ 1;

    if (p1 < p0) {
        p0 = x_index ^ 1;
        p1 = x_index;
    }
    queries.push((first_oracle[p0], first_oracle[p1]));
    indices.push(p0);
    x_index >>= 1;

    for oracle in oracles {
        let mut p0 = x_index;
        let mut p1 = x_index ^ 1;
        if (p1 < p0) {
            p0 = x_index ^ 1;
            p1 = x_index;
        }
        queries.push((oracle[p0], oracle[p1]));
        indices.push(p0);
        x_index >>= 1;
    }

    return (queries, indices);
}

fn get_merkle_path<H: Hash, F: PrimeField>(
    tree: &Vec<Vec<Output<H>>>,
    mut x_index: usize,
    root: bool,
) -> Vec<(Output<H>, Output<H>)> {
    let mut queries = Vec::with_capacity(tree.len());
    x_index >>= 1;
    for oracle in tree {
        let mut p0 = x_index;
        let mut p1 = x_index ^ 1;
        if (p1 < p0) {
            p0 = x_index ^ 1;
            p1 = x_index;
        }
        if (oracle.len() == 1) {
            if (root) {
                queries.push((oracle[0].clone(), oracle[0].clone()));
            }
            break;
        }
        queries.push((oracle[p0].clone(), oracle[p1].clone()));
        x_index >>= 1;
    }

    return queries;
}

fn write_merkle_path<H: Hash, F: PrimeField>(
    tree: &Vec<Vec<Output<H>>>,
    mut x_index: usize,
    transcript: &mut impl TranscriptWrite<Output<H>, F>,
) {
    x_index >>= 1;
    for oracle in tree {
        let mut p0 = x_index;
        let mut p1 = x_index ^ 1;
        if (p1 < p0) {
            p0 = x_index ^ 1;
            p1 = x_index;
        }
        if (oracle.len() == 1) {
            //	    transcript.write_commitment(&oracle[0]);
            break;
        }
        transcript.write_commitment(&oracle[p0]);
        transcript.write_commitment(&oracle[p1]);
        x_index >>= 1;
    }
}

fn authenticate_merkle_path<H: Hash, F: PrimeField>(
    path: &Vec<Vec<Output<H>>>,
    leaves: (F, F),
    mut x_index: usize,
) {
    let mut hasher = H::new();
    let mut hash = Output::<H>::default();
    hasher.update_field_element(&leaves.0);
    hasher.update_field_element(&leaves.1);
    hasher.finalize_into_reset(&mut hash);

    assert_eq!(hash, path[0][(x_index >> 1) % 2]);
    x_index >>= 1;
    for i in 0..path.len() {
        if (i + 1 == path.len()) {
            break;
        }
        let mut hasher = H::new();
        let mut hash = Output::<H>::default();
        hasher.update(&path[i][0]);
        hasher.update(&path[i][1]);
        hasher.finalize_into_reset(&mut hash);

        assert_eq!(hash, path[i + 1][(x_index >> 1) % 2]);
        x_index >>= 1;
    }
}

fn authenticate_merkle_path_root<H: Hash, F: PrimeField>(
    path: &Vec<Vec<Output<H>>>,
    leaves: (F, F),
    mut x_index: usize,
    root: &Output<H>,
) {
    let mut hasher = H::new();
    let mut hash = Output::<H>::default();
    hasher.update_field_element(&leaves.0);
    hasher.update_field_element(&leaves.1);
    hasher.finalize_into_reset(&mut hash);

    assert_eq!(hash, path[0][(x_index >> 1) % 2]);
    x_index >>= 1;
    for i in 0..path.len() - 1 {
        let mut hasher = H::new();
        let mut hash = Output::<H>::default();
        hasher.update(&path[i][0]);
        hasher.update(&path[i][1]);
        hasher.finalize_into_reset(&mut hash);

        assert_eq!(hash, path[i + 1][(x_index >> 1) % 2]);
        x_index >>= 1;
    }
    let mut hasher = H::new();
    let mut hash = Output::<H>::default();
    hasher.update(&path[path.len() - 1][0]);
    hasher.update(&path[path.len() - 1][1]);
    hasher.finalize_into_reset(&mut hash);
    assert_eq!(&hash, root);
}

pub fn interpolate2_weights<F: PrimeField>(points: [(F, F); 2], weight: F, x: F) -> F {
    // a0 -> a1
    // b0 -> b1
    // x  -> a1 + (x-a0)*(b1-a1)/(b0-a0)
    let (a0, a1) = points[0];
    let (b0, b1) = points[1];
    //    assert_ne!(a0, b0);
    a1 + (x - a0) * (b1 - a1) * weight
}

pub fn query_point<F: PrimeField>(
    block_length: usize,
    eval_index: usize,
    mut rng: &mut ChaCha12Rng,
    level: usize,
) -> F {
    let level_index = eval_index % (block_length);
    let mut el =
        query_root_table_from_rng::<F>(level, (level_index % (block_length >> 1)), &mut rng);

    if level_index >= (block_length >> 1) {
        el = -F::ONE * el;
    }

    return el;
}
pub fn query_root_table_from_rng<F: PrimeField>(
    level: usize,
    index: usize,
    rng: &mut ChaCha12Rng,
) -> F {
    let mut level_offset: u128 = 1;
    for lg_m in 1..=level {
        let half_m = 1 << (lg_m - 1);
        level_offset += half_m;
    }
    //this is 512  because of the implementation of random in the ff rust library
    //    let pos = ((level_offset + (index as u128)) * (512))
    let pos = ((level_offset + (index as u128))
        * ((F::NUM_BITS as usize).next_power_of_two() as u128))
        .checked_div(32)
        .unwrap();

    rng.set_word_pos(pos);
    rand_chacha::<F>(rng)
}

pub fn interpolate2<F: PrimeField>(points: [(F, F); 2], x: F) -> F {
    // a0 -> a1
    // b0 -> b1
    // x  -> a1 + (x-a0)*(b1-a1)/(b0-a0)
    let (a0, a1) = points[0];
    let (b0, b1) = points[1];
    assert_ne!(a0, b0);
    a1 + (x - a0) * (b1 - a1) * (b0 - a0).invert().unwrap()
}

fn degree_2_zero_plus_one<F: PrimeField>(poly: &Vec<F>) -> F {
    poly[0] + poly[0] + poly[1] + poly[2]
}

fn degree_2_eval<F: PrimeField>(poly: &Vec<F>, point: F) -> F {
    poly[0] + point * poly[1] + point * point * poly[2]
}

pub fn interpolate_over_boolean_hypercube<F: PrimeField>(mut evals: Vec<F>) -> Vec<F> {
    //iterate over array, replacing even indices with (evals[i] - evals[(i+1)])
    let n = log2_strict(evals.len());
    for i in 1..n + 1 {
        let chunk_size = 1 << i;
        evals.par_chunks_mut(chunk_size).for_each(|chunk| {
            let half_chunk = chunk_size >> 1;
            for j in half_chunk..chunk_size {
                chunk[j] = chunk[j] - chunk[j - half_chunk];
            }
        });
    }
    reverse_index_bits_in_place(&mut evals);
    evals
}

pub fn multilinear_evaluation_ztoa<F: PrimeField>(poly: &mut Vec<F>, point: &Vec<F>) {
    let n = log2_strict(poly.len());
    //    assert_eq!(point.len(),n);
    for p in point {
        poly.par_chunks_mut(2).for_each(|chunk| {
            chunk[0] = chunk[0] + *p * chunk[1];
            chunk[1] = chunk[0];
        });
        poly.dedup();
    }
}
#[test]
fn bench_multilinear_eval() {
    use crate::util::ff_255::ff255::Ft255;
    for i in 10..26 {
        let mut rng = ChaCha12Rng::from_entropy();
        let mut poly = rand_vec::<Ft255>(1 << i, &mut rng);
        let point = rand_vec::<Ft255>(i, &mut rng);
        let now = Instant::now();
        multilinear_evaluation_ztoa(&mut poly, &point);
        println!(
            "time for multilinear eval degree i {:?} : {:?}",
            i,
            now.elapsed().as_millis()
        );
    }
}
fn from_raw_bytes<F: PrimeField>(bytes: &Vec<u8>) -> F {
    let mut res = F::ZERO;
    bytes.into_iter().for_each(|b| {
        res += F::from(u64::from(*b));
    });
    res
}

#[cfg(test)]
mod test {
    use crate::util::transcript::{
        FieldTranscript, FieldTranscriptRead, FieldTranscriptWrite, InMemoryTranscript,
        TranscriptRead, TranscriptWrite,
    };
    use crate::{
        pcs::multilinear::{
            basefold::Basefold,
            test::{run_batch_commit_open_verify, run_commit_open_verify},
        },
        util::{
            hash::{Hash, Keccak256, Output},
            new_fields::{Mersenne127, Mersenne61},
            transcript::{Blake2sTranscript, Keccak256Transcript},
        },
    };
    use halo2_curves::{ff::Field, secp256k1::Fp};
    use std::io;

    use crate::util::arithmetic::PrimeField;

    use crate::pcs::multilinear::basefold::Instant;
    use blake2::{digest::FixedOutputReset, Blake2s256};
    type Pcs = Basefold<Mersenne61, Blake2s256>;

    #[test]
    fn commit_open_verify() {
        run_commit_open_verify::<_, Pcs, Blake2sTranscript<_>>();
    }

    #[test]
    fn batch_commit_open_verify() {
        run_batch_commit_open_verify::<_, Pcs, Blake2sTranscript<_>>();
    }

    struct PretendHash {}
    #[test]
    fn test_sha3_hashes() {
        use blake2::digest::FixedOutputReset;

        type H = Keccak256;
        let lots_of_hashes = Instant::now();
        let values = vec![Mersenne127::ONE; 2000];
        let mut hashes = vec![Output::<H>::default(); (values.len() >> 1)];
        for (i, mut hash) in hashes.iter_mut().enumerate() {
            let mut hasher = H::new();
            hasher.update_field_element(&values[i + i]);
            hasher.update_field_element(&values[i + i + 1]);
            hasher.finalize_into_reset(&mut hash);
        }
        println!("lots of hashes sha3 time {:?}", lots_of_hashes.elapsed());

        let hash_alot = Instant::now();
        let mut hasher = H::new();
        for i in 0..2000 {
            hasher.update_field_element(&values[i]);
        }
        let mut hash = Output::<H>::default();
        hasher.finalize_into_reset(&mut hash);
        println!("hash a lot sha3 time {:?}", hash_alot.elapsed());
    }

    #[test]
    fn test_blake2b_hashes() {
        use blake2::{digest::FixedOutputReset, Blake2b512, Blake2s256};

        type H = Blake2s256;
        let lots_of_hashes = Instant::now();
        let values = vec![Mersenne127::ONE; 2000];
        let mut hashes = vec![Output::<H>::default(); (values.len() >> 1)];
        for (i, mut hash) in hashes.iter_mut().enumerate() {
            let mut hasher = H::new();
            hasher.update_field_element(&values[i + i]);
            hasher.update_field_element(&values[i + i + 1]);
            hasher.finalize_into_reset(&mut hash);
        }
        println!("lots of hashes blake2 time {:?}", lots_of_hashes.elapsed());

        let hash_alot = Instant::now();
        let mut hasher = H::new();
        for i in 0..2000 {
            hasher.update_field_element(&values[i]);
        }
        let mut hash = Output::<H>::default();
        hasher.finalize_into_reset(&mut hash);
        println!("hash alot blake2 time {:?}", hash_alot.elapsed());
    }

    #[test]
    fn test_blake2b_no_finalize() {
        use blake2::{digest::FixedOutputReset, Blake2b512, Blake2s256};

        type H = Blake2s256;
        let lots_of_hashes = Instant::now();
        let values = vec![Mersenne127::ONE; 2000];
        let mut hashes = vec![Output::<H>::default(); (values.len() >> 1)];
        for (i, mut hash) in hashes.iter_mut().enumerate() {
            let mut hasher = H::new();
            let f1 = values[i + 1].to_repr();
            let f2 = values[i + i + 1].to_repr();
            let data = [f1.as_ref(), f2.as_ref()].concat();
            //	    hasher.update_field_element(&values[i + i]);
            //	    hasher.update_field_element(&values[i+ i + 1]);
            *hash = H::digest(&data);
        }
        println!(
            "lots of hashes blake2 time no finalize{:?}",
            lots_of_hashes.elapsed()
        );

        let hash_alot = Instant::now();
        let mut hasher = H::new();
        for i in 0..2000 {
            hasher.update_field_element(&values[i]);
        }
        let mut hash = Output::<H>::default();
        hasher.finalize_into_reset(&mut hash);
        println!("hash alot blake2 time no finalize{:?}", hash_alot.elapsed());
    }

    #[test]
    fn test_blake2b_simd_hashes() {
        use blake2b_simd::{blake2b, many::update_many, State};
        use ff::PrimeField;
        let lots_of_hashes = Instant::now();
        let values = vec![Mersenne127::ONE; 2000];
        let mut states = vec![State::new(); 1000];

        for (i, mut hash) in states.iter_mut().enumerate() {
            hash.update(&values[i + i].to_repr().as_ref());
            hash.update(&values[i + i + 1].to_repr().as_ref());
            hash.finalize();
        }
        println!(
            "lots of hashes blake2simd time {:?}",
            lots_of_hashes.elapsed()
        );

        let hash_alot = Instant::now();
        let mut state = State::new();
        for i in 0..2000 {
            state.update(values[i].to_repr().as_ref());
        }
        let hash = state.finalize();
        println!("hash alot blake2simd time {:?}", hash_alot.elapsed());
    }
}

fn reed_solomon_into<F: Field>(input: &[F], mut target: impl AsMut<[F]>) {
    target
        .as_mut()
        .iter_mut()
        .zip(steps(F::ONE))
        .for_each(|(target, x)| *target = horner(input, &x));
}

fn virtual_open<F: PrimeField>(
    num_vars: usize,
    num_rounds: usize,
    eq: &mut Vec<F>,
    bh_evals: &mut Vec<F>,
    last_oracle: &Vec<F>,
    point: &Vec<F>,
    challenges: &mut Vec<F>,
    table: &Vec<Vec<(F, F)>>,
    sum_check_oracles: &mut Vec<Vec<F>>,
) {
    let mut rng = ChaCha12Rng::from_entropy();
    let rounds = num_vars - num_rounds;

    let mut oracles = Vec::with_capacity(rounds);
    let mut new_oracle = last_oracle;
    for round in 0..rounds {
        let challenge: F = rand_chacha(&mut rng);
        challenges.push(challenge);
        sum_check_oracles.push(sum_check_challenge_round(eq, bh_evals, challenge));
        oracles.push(basefold_one_round_by_interpolation_weights::<F>(
            &table,
            round + num_rounds,
            &new_oracle,
            challenge,
        ));
        new_oracle = &oracles[round];
    }

    let mut no = new_oracle.clone();
    no.dedup();
    assert_eq!(no.len(), 1);

    //verify it information-theoretically

    let mut eq_r_ = F::ONE;
    for i in 0..challenges.len() {
        eq_r_ = eq_r_ * (challenges[i] * point[i] + (F::ONE - challenges[i]) * (F::ONE - point[i]));
    }
    let last_challenge = challenges[challenges.len() - 1];
    assert_eq!(
        degree_2_eval(&sum_check_oracles[challenges.len() - 1], last_challenge),
        eq_r_ * no[0]
    );
}
//outputs (trees, sumcheck_oracles, oracles, bh_evals, eq, eval)
fn commit_phase<F: PrimeField, H: Hash>(
    point: &Point<F, MultilinearPolynomial<F>>,
    comm: &BasefoldCommitment<F, H>,
    transcript: &mut impl TranscriptWrite<Output<H>, F>,
    num_vars: usize,
    num_rounds: usize,
    table_w_weights: &Vec<Vec<(F, F)>>,
) -> (
    Vec<Vec<Vec<Output<H>>>>,
    Vec<Vec<F>>,
    Vec<Vec<F>>,
    Vec<F>,
    Vec<F>,
    F,
) {
    let mut oracles = Vec::with_capacity(num_vars);

    let mut trees = Vec::with_capacity(num_vars);

    let mut new_tree = &comm.codeword_tree;
    let mut root = new_tree[new_tree.len() - 1][0].clone();
    let mut new_oracle = &comm.codeword;

    let num_rounds = num_rounds; //pp.table.len() - pp.log_rate;
    let mut eq = build_eq_x_r_vec::<F>(&point).unwrap();

    let mut eval = F::ZERO;
    let mut bh_evals = Vec::with_capacity(1 << num_vars);
    for i in 0..eq.len() {
        eval = eval + comm.bh_evals[i] * eq[i];
        bh_evals.push(comm.bh_evals[i]);
    }

    let mut sum_check_oracles = Vec::with_capacity(num_rounds + 1);
    sum_check_oracles.push(sum_check_first_round::<F>(&mut eq, &mut bh_evals));

    for i in 0..(num_rounds) {
        transcript.write_commitment(&root).unwrap();
        let challenge: F = transcript.squeeze_challenge();
        let sumcheck = Instant::now();
        sum_check_oracles.push(sum_check_challenge_round(&mut eq, &mut bh_evals, challenge));

        oracles.push(basefold_one_round_by_interpolation_weights::<F>(
            &table_w_weights,
            i,
            new_oracle,
            challenge,
        ));

        new_oracle = &oracles[i];
        trees.push(merkelize::<F, H>(&new_oracle));
        root = trees[i][trees[i].len() - 1][0].clone();
    }

    transcript.write_commitment(&root).unwrap();
    return (trees, sum_check_oracles, oracles, bh_evals, eq, eval);
}

fn query_phase<F: PrimeField, H: Hash>(
    transcript: &mut impl TranscriptWrite<Output<H>, F>,
    comm: &BasefoldCommitment<F, H>,
    oracles: &Vec<Vec<F>>,
    num_verifier_queries: usize,
) -> (Vec<(Vec<(F, F)>, Vec<usize>)>, Vec<usize>) {
    let mut queries = transcript.squeeze_challenges(num_verifier_queries);

    let queries_usize: Vec<usize> = queries
        .iter()
        .map(|x_index| {
            let x_rep = (*x_index).to_repr();
            let mut x: &[u8] = x_rep.as_ref();
            let (int_bytes, rest) = x.split_at(std::mem::size_of::<u32>());
            let x_int: u32 = u32::from_be_bytes(int_bytes.try_into().unwrap());
            ((x_int as usize) % comm.codeword.len()).into()
        })
        .collect_vec();

    (
        queries_usize
            .iter()
            .map(|x_index| {
                return basefold_get_query::<F>(&comm.codeword, &oracles, *x_index);
            })
            .collect(),
        queries_usize,
    )
}

fn verifier_query_phase<F: PrimeField, H: Hash>(
    query_challenges: &Vec<F>,
    query_merkle_paths: &Vec<Vec<Vec<Vec<Output<H>>>>>,
    sum_check_oracles: &Vec<Vec<F>>,
    fold_challenges: &Vec<F>,
    queries: &Vec<Vec<&[F]>>,
    num_rounds: usize,
    num_vars: usize,
    log_rate: usize,
    roots: &Vec<Output<H>>,
    rng: ChaCha12Rng,
    eval: &F,
) -> Vec<usize> {
    let n = (1 << (num_vars + log_rate));
    let mut queries_usize: Vec<usize> = query_challenges
        .par_iter()
        .map(|x_index| {
            let x_repr = (*x_index).to_repr();
            let mut x: &[u8] = x_repr.as_ref();
            let (int_bytes, rest) = x.split_at(std::mem::size_of::<u32>());
            let x_int: u32 = u32::from_be_bytes(int_bytes.try_into().unwrap());
            ((x_int as usize) % n).into()
        })
        .collect();

    queries_usize
        .par_iter_mut()
        .enumerate()
        .for_each(|(qi, query_index)| {
            let mut rng = rng.clone();
            let mut cur_index = *query_index;
            let mut cur_queries = &queries[qi];

            for i in 0..num_rounds {
                let temp = cur_index;
                let mut other_index = cur_index ^ 1;
                if (other_index < cur_index) {
                    cur_index = other_index;
                    other_index = temp;
                }

                assert_eq!(cur_index % 2, 0);

                let ri0 = reverse_bits(cur_index, num_vars + log_rate - i);
                let ri1 = reverse_bits(other_index, num_vars + log_rate - i);

                let x0 = query_point(
                    1 << (num_vars + log_rate - i),
                    ri0,
                    &mut rng,
                    num_vars + log_rate - i - 1,
                );
                let x1 = query_point(
                    1 << (num_vars + log_rate - i),
                    ri1,
                    &mut rng,
                    num_vars + log_rate - i - 1,
                );
                assert_eq!(x0, -F::ONE * x1);

                let res = interpolate2(
                    [(x0, cur_queries[i][0]), (x1, cur_queries[i][1])],
                    fold_challenges[i],
                );

                assert_eq!(res, cur_queries[i + 1][(cur_index >> 1) % 2]);

                authenticate_merkle_path_root::<H, F>(
                    &query_merkle_paths[qi][i],
                    (cur_queries[i][0], cur_queries[i][1]),
                    cur_index,
                    &roots[i],
                );

                cur_index >>= 1;
            }
        });

    assert_eq!(eval, &degree_2_zero_plus_one(&sum_check_oracles[0]));

    for i in 0..fold_challenges.len() - 1 {
        assert_eq!(
            degree_2_eval(&sum_check_oracles[i], fold_challenges[i]),
            degree_2_zero_plus_one(&sum_check_oracles[i + 1])
        );
    }
    return queries_usize;
}
